"Name","_wandb","z_score_roc_auc"
"pile_uspto_opt-6-7b_gen_attacked_dipper_eval","","0.9981056425774296"
"core_algorithm-3_50_200_dipper_high_eval","","0.9976770273508664"
"pile_pubmed_opt-6-7b_gen_attacked_dipper_eval","","0.997902981505102"
"pile_pubmed_opt-6-7b_gen_attacked_gpt_eval","","0.997902981505102"
"pile_free_law_opt-6-7b_gen_attacked_dipper_eval","","0.8658174842814726"
"pile_uspto_llama-7b-base_gen_attacked_dipper_eval","","0.9994435"
"core_simple_1_50_200_dipper_high_eval","","0.999471101898308"
"pile_uspto_opt-6-7b_gen_attacked_gpt_eval","","0.9981056425774296"
"pile_pubmed_llama-7b-base_gen_attacked_gpt_eval","","0.9987910194400323"
"core_algorithm-3_50_200_gpt_p4_eval","","0.9976770273508664"
"pile_pubmed_llama-7b-base_gen_attacked_dipper_eval","","0.9987910194400323"
"pile_uspto_llama-7b-base_gen_attacked_gpt_eval","","0.9994435"
"core_wikitext_llama-7b-base_gpt_p4_eval","","0.9991254337644688"
"pile_free_law_llama-7b-base_gen_attacked_dipper_eval","","0.9928320619574396"
"pile_free_law_opt-6-7b_gen_attacked_gpt_eval","","0.8658174842814726"
"core_simple_1_50_200_gpt_p4_eval","","0.999471101898308"
"pile_github_opt-6-7b_gen_attacked_gpt_eval","","0.8187593252488055"
"pile_pubmed_llama-7b-vicuna-v1-1_gen_attacked_dipper_eval","","0.9914204359690156"
"pile_pubmed_llama-7b-vicuna-v1-1_gen_attacked_gpt_eval","","0.9914204359690156"
"pile_uspto_llama-7b-vicuna-v1-1_gen_attacked_gpt_eval","","0.9960996171329994"
"pile_uspto_llama-7b-vicuna-v1-1_gen_attacked_dipper_eval","","0.9960996171329994"
"pile_free_law_llama-7b-vicuna-v1-1_gen_attacked_dipper_eval","","0.9796164185827118"
"core_c4_llama-7b-base_gpt_p4_eval","","0.9816242435030258"
"pile_free_law_llama-7b-base_gen_attacked_gpt_eval","","0.9928320619574396"
"pile_free_law_llama-7b-vicuna-v1-1_gen_attacked_gpt_eval","","0.9796164185827118"
"pile_github_opt-6-7b_gen_attacked_dipper_eval","","0.8187593252488055"
"pile_github_llama-7b-base_gen_attacked_dipper_eval","","0.8912796635851082"
"pile_github_llama-7b-vicuna-v1-1_gen_attacked_dipper_eval","","0.8474932456642787"
"pile_github_llama-7b-base_gen_attacked_gpt_eval","","0.8912796635851082"
"pile_github_llama-7b-vicuna-v1-1_gen_attacked_gpt_eval","","0.8474932456642787"