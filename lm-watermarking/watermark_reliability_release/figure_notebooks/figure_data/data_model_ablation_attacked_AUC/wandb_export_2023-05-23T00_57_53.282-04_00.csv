"Name","_wandb","attacked_z_score_roc_auc"
"pile_uspto_opt-6-7b_gen_attacked_dipper_eval","","0.9753168387326452"
"core_algorithm-3_50_200_dipper_high_eval","","0.9655157308495406"
"pile_pubmed_opt-6-7b_gen_attacked_dipper_eval","","0.9632824457908165"
"pile_pubmed_opt-6-7b_gen_attacked_gpt_eval","","0.9568666294642856"
"pile_free_law_opt-6-7b_gen_attacked_dipper_eval","","0.9405287217663212"
"pile_uspto_llama-7b-base_gen_attacked_dipper_eval","","0.9256885"
"core_simple_1_50_200_dipper_high_eval","","0.9255698604417844"
"pile_uspto_opt-6-7b_gen_attacked_gpt_eval","","0.9210461908152368"
"pile_pubmed_llama-7b-base_gen_attacked_gpt_eval","","0.9179670881046714"
"core_algorithm-3_50_200_gpt_p4_eval","","0.9056114670416175"
"pile_pubmed_llama-7b-base_gen_attacked_dipper_eval","","0.9042177051707364"
"pile_uspto_llama-7b-base_gen_attacked_gpt_eval","","0.9009815"
"core_wikitext_llama-7b-base_gpt_p4_eval","","0.900680919216676"
"pile_free_law_llama-7b-base_gen_attacked_dipper_eval","","0.8923556514067247"
"pile_free_law_opt-6-7b_gen_attacked_gpt_eval","","0.8802090131481627"
"core_simple_1_50_200_gpt_p4_eval","","0.8566863352541482"
"pile_github_opt-6-7b_gen_attacked_gpt_eval","","0.8413031142362819"
"pile_pubmed_llama-7b-vicuna-v1-1_gen_attacked_dipper_eval","","0.8386006111362607"
"pile_pubmed_llama-7b-vicuna-v1-1_gen_attacked_gpt_eval","","0.8348427047180726"
"pile_uspto_llama-7b-vicuna-v1-1_gen_attacked_gpt_eval","","0.8304090421950511"
"pile_uspto_llama-7b-vicuna-v1-1_gen_attacked_dipper_eval","","0.8286102445806989"
"pile_free_law_llama-7b-vicuna-v1-1_gen_attacked_dipper_eval","","0.8151858767701917"
"core_c4_llama-7b-base_gpt_p4_eval","","0.8123616055535778"
"pile_free_law_llama-7b-base_gen_attacked_gpt_eval","","0.8088328094227591"
"pile_free_law_llama-7b-vicuna-v1-1_gen_attacked_gpt_eval","","0.7267955497391483"
"pile_github_opt-6-7b_gen_attacked_dipper_eval","","0.7084074260440053"
"pile_github_llama-7b-base_gen_attacked_dipper_eval","","0.6838108837870842"
"pile_github_llama-7b-vicuna-v1-1_gen_attacked_dipper_eval","","0.6428489749536344"
"pile_github_llama-7b-base_gen_attacked_gpt_eval","","0.6160232931396354"
"pile_github_llama-7b-vicuna-v1-1_gen_attacked_gpt_eval","","0.5870321985003151"